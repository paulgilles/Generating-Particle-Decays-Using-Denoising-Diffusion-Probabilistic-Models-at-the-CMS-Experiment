# Argumente aus image_train create_arg_parser()
lr_anneal_steps=200000
preprocessing=true
min_max_norm=true #Wenn True, verwendet Mapping zwischen [-1, 1], sonst
                   #Normierung durch mean und std
preprocess_count_number = 10
preprocess_intervals = [[0.2, 0.2], [0.2, 0.2]]
emb_layer=[0,1,2,3,4,5,6]
norm_layer=[] #number of nodes in norm_layer has to be even
structure=[512,512,512,512,512,512,512]
dropout_layer=[]
emb_nodes=32 #need to be 4 * i with i e Z
batch_size=128
microbatch=16  #@todo ist es richtig, dass beim sampling batchsize = microbatch sein muss?
log_interval=200
save_interval=50000

lr=1e-4
weight_decay=0.0
resume_checkpoint=""
use_fp16=false
schedule_sampler="loss-second-moment"
fp16_scale_growth=1e-3
ema_rate="0.9999"  # comma-separated list of EMA values

# Argumente aus script_until.py aus model_and_diffusion_defaults 
dropout=0.3
learn_sigma=true
sigma_small=true
class_cond=false
diffusion_steps=1000
noise_schedule="cosine"
timestep_respacing=""
use_kl=false
predict_xstart=false
rescale_timesteps=true
rescale_learned_sigmas=true
use_checkpoint=false
use_scale_shift_norm=false

