Logging to /home/paulgilles/Bachelorarbeit/modified-improved-diffusion-main/Models/2023-06-22_17-28-17
creating model and diffusion...
creating data loader...
training...
------------------------
| grad_norm | 1.08     |
| loss      | 1.1      |
| loss_q0   | 1.35     |
| loss_q1   | 0.883    |
| loss_q2   | 0.991    |
| loss_q3   | 1.21     |
| mse       | 1.08     |
| mse_q0    | 1.31     |
| mse_q1    | 0.878    |
| mse_q2    | 0.986    |
| mse_q3    | 1.16     |
| samples   | 128      |
| step      | 0        |
| vb        | 0.023    |
| vb_q0     | 0.0371   |
| vb_q1     | 0.0044   |
| vb_q2     | 0.00494  |
| vb_q3     | 0.0475   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.11     |
| loss      | 1.02     |
| loss_q0   | 1.08     |
| loss_q1   | 0.877    |
| loss_q2   | 0.977    |
| loss_q3   | 1.16     |
| mse       | 1        |
| mse_q0    | 1.07     |
| mse_q1    | 0.872    |
| mse_q2    | 0.972    |
| mse_q3    | 1.11     |
| samples   | 256      |
| step      | 1        |
| vb        | 0.018    |
| vb_q0     | 0.0182   |
| vb_q1     | 0.00435  |
| vb_q2     | 0.00483  |
| vb_q3     | 0.0452   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.12     |
| loss      | 1.08     |
| loss_q0   | 1.1      |
| loss_q1   | 0.992    |
| loss_q2   | 0.921    |
| loss_q3   | 1.3      |
| mse       | 1.04     |
| mse_q0    | 1.02     |
| mse_q1    | 0.987    |
| mse_q2    | 0.916    |
| mse_q3    | 1.23     |
| samples   | 384      |
| step      | 2        |
| vb        | 0.0389   |
| vb_q0     | 0.0839   |
| vb_q1     | 0.00508  |
| vb_q2     | 0.00461  |
| vb_q3     | 0.0638   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.23     |
| loss      | 0.958    |
| loss_q0   | 0.966    |
| loss_q1   | 1.02     |
| loss_q2   | 0.865    |
| loss_q3   | 0.972    |
| mse       | 0.945    |
| mse_q0    | 0.939    |
| mse_q1    | 1.01     |
| mse_q2    | 0.86     |
| mse_q3    | 0.961    |
| samples   | 512      |
| step      | 3        |
| vb        | 0.0123   |
| vb_q0     | 0.027    |
| vb_q1     | 0.00509  |
| vb_q2     | 0.00436  |
| vb_q3     | 0.0115   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.41     |
| loss      | 1.14     |
| loss_q0   | 1.18     |
| loss_q1   | 1.09     |
| loss_q2   | 1.16     |
| loss_q3   | 1.13     |
| mse       | 1.1      |
| mse_q0    | 1.15     |
| mse_q1    | 1.08     |
| mse_q2    | 1.15     |
| mse_q3    | 1.02     |
| samples   | 640      |
| step      | 4        |
| vb        | 0.0389   |
| vb_q0     | 0.0295   |
| vb_q1     | 0.00549  |
| vb_q2     | 0.00596  |
| vb_q3     | 0.118    |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.16     |
| loss      | 1.09     |
| loss_q0   | 1.05     |
| loss_q1   | 1.1      |
| loss_q2   | 1.18     |
| loss_q3   | 1.04     |
| mse       | 1.07     |
| mse_q0    | 1.03     |
| mse_q1    | 1.1      |
| mse_q2    | 1.17     |
| mse_q3    | 1        |
| samples   | 768      |
| step      | 5        |
| vb        | 0.0191   |
| vb_q0     | 0.0221   |
| vb_q1     | 0.00553  |
| vb_q2     | 0.00578  |
| vb_q3     | 0.04     |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1        |
| loss      | 1.07     |
| loss_q0   | 1.08     |
| loss_q1   | 1.18     |
| loss_q2   | 0.933    |
| loss_q3   | 1.12     |
| mse       | 1        |
| mse_q0    | 1.03     |
| mse_q1    | 1.18     |
| mse_q2    | 0.929    |
| mse_q3    | 0.939    |
| samples   | 896      |
| step      | 6        |
| vb        | 0.0615   |
| vb_q0     | 0.0503   |
| vb_q1     | 0.00597  |
| vb_q2     | 0.00467  |
| vb_q3     | 0.185    |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.35     |
| loss      | 1.06     |
| loss_q0   | 1.12     |
| loss_q1   | 1.2      |
| loss_q2   | 1.06     |
| loss_q3   | 0.847    |
| mse       | 1.04     |
| mse_q0    | 1.1      |
| mse_q1    | 1.19     |
| mse_q2    | 1.06     |
| mse_q3    | 0.811    |
| samples   | 1.02e+03 |
| step      | 7        |
| vb        | 0.0173   |
| vb_q0     | 0.0227   |
| vb_q1     | 0.00599  |
| vb_q2     | 0.00537  |
| vb_q3     | 0.0363   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.33     |
| loss      | 1.17     |
| loss_q0   | 1.05     |
| loss_q1   | 0.969    |
| loss_q2   | 1.1      |
| loss_q3   | 1.55     |
| mse       | 1.05     |
| mse_q0    | 1.03     |
| mse_q1    | 0.964    |
| mse_q2    | 1.09     |
| mse_q3    | 1.11     |
| samples   | 1.15e+03 |
| step      | 8        |
| vb        | 0.118    |
| vb_q0     | 0.0205   |
| vb_q1     | 0.00505  |
| vb_q2     | 0.00556  |
| vb_q3     | 0.436    |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.19     |
| loss      | 1.02     |
| loss_q0   | 0.962    |
| loss_q1   | 1.17     |
| loss_q2   | 1.02     |
| loss_q3   | 0.911    |
| mse       | 1        |
| mse_q0    | 0.944    |
| mse_q1    | 1.16     |
| mse_q2    | 1.02     |
| mse_q3    | 0.878    |
| samples   | 1.28e+03 |
| step      | 9        |
| vb        | 0.0157   |
| vb_q0     | 0.018    |
| vb_q1     | 0.00577  |
| vb_q2     | 0.00515  |
| vb_q3     | 0.0338   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.863    |
| loss      | 0.991    |
| loss_q0   | 0.778    |
| loss_q1   | 1.17     |
| loss_q2   | 1.04     |
| loss_q3   | 0.983    |
| mse       | 0.98     |
| mse_q0    | 0.769    |
| mse_q1    | 1.16     |
| mse_q2    | 1.04     |
| mse_q3    | 0.959    |
| samples   | 1.41e+03 |
| step      | 10       |
| vb        | 0.0113   |
| vb_q0     | 0.0093   |
| vb_q1     | 0.0059   |
| vb_q2     | 0.00545  |
| vb_q3     | 0.0236   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.3      |
| loss      | 0.981    |
| loss_q0   | 1.09     |
| loss_q1   | 0.955    |
| loss_q2   | 0.91     |
| loss_q3   | 1.04     |
| mse       | 0.969    |
| mse_q0    | 1.08     |
| mse_q1    | 0.95     |
| mse_q2    | 0.906    |
| mse_q3    | 1.01     |
| samples   | 1.54e+03 |
| step      | 11       |
| vb        | 0.0116   |
| vb_q0     | 0.0191   |
| vb_q1     | 0.00481  |
| vb_q2     | 0.0047   |
| vb_q3     | 0.0276   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.21     |
| loss      | 1.1      |
| loss_q0   | 1.07     |
| loss_q1   | 0.973    |
| loss_q2   | 1.08     |
| loss_q3   | 1.23     |
| mse       | 1.07     |
| mse_q0    | 1.03     |
| mse_q1    | 0.968    |
| mse_q2    | 1.07     |
| mse_q3    | 1.19     |
| samples   | 1.66e+03 |
| step      | 12       |
| vb        | 0.0252   |
| vb_q0     | 0.0376   |
| vb_q1     | 0.00486  |
| vb_q2     | 0.00555  |
| vb_q3     | 0.0444   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.5      |
| loss      | 1.21     |
| loss_q0   | 1.23     |
| loss_q1   | 1.32     |
| loss_q2   | 1.12     |
| loss_q3   | 1.18     |
| mse       | 1.18     |
| mse_q0    | 1.2      |
| mse_q1    | 1.31     |
| mse_q2    | 1.11     |
| mse_q3    | 1.1      |
| samples   | 1.79e+03 |
| step      | 13       |
| vb        | 0.0272   |
| vb_q0     | 0.0304   |
| vb_q1     | 0.00677  |
| vb_q2     | 0.00557  |
| vb_q3     | 0.0714   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.36     |
| loss      | 0.967    |
| loss_q0   | 1.14     |
| loss_q1   | 0.877    |
| loss_q2   | 0.917    |
| loss_q3   | 0.947    |
| mse       | 0.956    |
| mse_q0    | 1.11     |
| mse_q1    | 0.873    |
| mse_q2    | 0.912    |
| mse_q3    | 0.932    |
| samples   | 1.92e+03 |
| step      | 14       |
| vb        | 0.0118   |
| vb_q0     | 0.0235   |
| vb_q1     | 0.00451  |
| vb_q2     | 0.00451  |
| vb_q3     | 0.0154   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.12     |
| loss      | 0.983    |
| loss_q0   | 0.891    |
| loss_q1   | 1.07     |
| loss_q2   | 0.99     |
| loss_q3   | 1.01     |
| mse       | 0.966    |
| mse_q0    | 0.874    |
| mse_q1    | 1.06     |
| mse_q2    | 0.985    |
| mse_q3    | 0.967    |
| samples   | 2.05e+03 |
| step      | 15       |
| vb        | 0.017    |
| vb_q0     | 0.0176   |
| vb_q1     | 0.0053   |
| vb_q2     | 0.00491  |
| vb_q3     | 0.0391   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.09     |
| loss      | 1.04     |
| loss_q0   | 1.08     |
| loss_q1   | 1.04     |
| loss_q2   | 1.02     |
| loss_q3   | 1.01     |
| mse       | 1.02     |
| mse_q0    | 1.05     |
| mse_q1    | 1.03     |
| mse_q2    | 1.01     |
| mse_q3    | 0.982    |
| samples   | 2.18e+03 |
| step      | 16       |
| vb        | 0.0161   |
| vb_q0     | 0.027    |
| vb_q1     | 0.00522  |
| vb_q2     | 0.00512  |
| vb_q3     | 0.0272   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.15     |
| loss      | 1.06     |
| loss_q0   | 1.03     |
| loss_q1   | 1.11     |
| loss_q2   | 1.02     |
| loss_q3   | 1.08     |
| mse       | 1.04     |
| mse_q0    | 0.986    |
| mse_q1    | 1.11     |
| mse_q2    | 1.01     |
| mse_q3    | 1.04     |
| samples   | 2.3e+03  |
| step      | 17       |
| vb        | 0.0251   |
| vb_q0     | 0.0426   |
| vb_q1     | 0.0055   |
| vb_q2     | 0.0051   |
| vb_q3     | 0.0472   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.42     |
| loss      | 1.11     |
| loss_q0   | 1.13     |
| loss_q1   | 1.12     |
| loss_q2   | 0.94     |
| loss_q3   | 1.22     |
| mse       | 1.08     |
| mse_q0    | 1.09     |
| mse_q1    | 1.11     |
| mse_q2    | 0.935    |
| mse_q3    | 1.2      |
| samples   | 2.43e+03 |
| step      | 18       |
| vb        | 0.0213   |
| vb_q0     | 0.0433   |
| vb_q1     | 0.00565  |
| vb_q2     | 0.00497  |
| vb_q3     | 0.0249   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.22     |
| loss      | 1.23     |
| loss_q0   | 1.12     |
| loss_q1   | 1.03     |
| loss_q2   | 1.34     |
| loss_q3   | 1.47     |
| mse       | 1.13     |
| mse_q0    | 1.1      |
| mse_q1    | 1.03     |
| mse_q2    | 1.33     |
| mse_q3    | 1.15     |
| samples   | 2.56e+03 |
| step      | 19       |
| vb        | 0.0933   |
| vb_q0     | 0.0206   |
| vb_q1     | 0.00512  |
| vb_q2     | 0.00671  |
| vb_q3     | 0.317    |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.11     |
| loss      | 0.987    |
| loss_q0   | 0.981    |
| loss_q1   | 0.939    |
| loss_q2   | 0.963    |
| loss_q3   | 1.08     |
| mse       | 0.952    |
| mse_q0    | 0.956    |
| mse_q1    | 0.935    |
| mse_q2    | 0.958    |
| mse_q3    | 0.96     |
| samples   | 2.69e+03 |
| step      | 20       |
| vb        | 0.0351   |
| vb_q0     | 0.0244   |
| vb_q1     | 0.00451  |
| vb_q2     | 0.00492  |
| vb_q3     | 0.119    |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.956    |
| loss      | 0.991    |
| loss_q0   | 0.983    |
| loss_q1   | 1.01     |
| loss_q2   | 0.974    |
| loss_q3   | 0.998    |
| mse       | 0.978    |
| mse_q0    | 0.967    |
| mse_q1    | 1.01     |
| mse_q2    | 0.969    |
| mse_q3    | 0.97     |
| samples   | 2.82e+03 |
| step      | 21       |
| vb        | 0.0134   |
| vb_q0     | 0.0156   |
| vb_q1     | 0.00513  |
| vb_q2     | 0.00487  |
| vb_q3     | 0.0284   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.02     |
| loss      | 0.999    |
| loss_q0   | 1.13     |
| loss_q1   | 0.969    |
| loss_q2   | 0.926    |
| loss_q3   | 0.966    |
| mse       | 0.975    |
| mse_q0    | 1.07     |
| mse_q1    | 0.964    |
| mse_q2    | 0.921    |
| mse_q3    | 0.941    |
| samples   | 2.94e+03 |
| step      | 22       |
| vb        | 0.0248   |
| vb_q0     | 0.0602   |
| vb_q1     | 0.00478  |
| vb_q2     | 0.00447  |
| vb_q3     | 0.0252   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.4      |
| loss      | 1.16     |
| loss_q0   | 1.28     |
| loss_q1   | 0.961    |
| loss_q2   | 1        |
| loss_q3   | 1.33     |
| mse       | 1.13     |
| mse_q0    | 1.25     |
| mse_q1    | 0.957    |
| mse_q2    | 1        |
| mse_q3    | 1.26     |
| samples   | 3.07e+03 |
| step      | 23       |
| vb        | 0.0332   |
| vb_q0     | 0.0372   |
| vb_q1     | 0.0049   |
| vb_q2     | 0.00516  |
| vb_q3     | 0.072    |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.781    |
| loss      | 1.08     |
| loss_q0   | 0.96     |
| loss_q1   | 1.23     |
| loss_q2   | 1.04     |
| loss_q3   | 1.09     |
| mse       | 1.06     |
| mse_q0    | 0.939    |
| mse_q1    | 1.23     |
| mse_q2    | 1.04     |
| mse_q3    | 1.06     |
| samples   | 3.2e+03  |
| step      | 24       |
| vb        | 0.0153   |
| vb_q0     | 0.0215   |
| vb_q1     | 0.00602  |
| vb_q2     | 0.0053   |
| vb_q3     | 0.0275   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.03     |
| loss      | 1.05     |
| loss_q0   | 1.11     |
| loss_q1   | 1.04     |
| loss_q2   | 0.963    |
| loss_q3   | 1.07     |
| mse       | 1.03     |
| mse_q0    | 1.08     |
| mse_q1    | 1.04     |
| mse_q2    | 0.958    |
| mse_q3    | 1.05     |
| samples   | 3.33e+03 |
| step      | 25       |
| vb        | 0.0183   |
| vb_q0     | 0.0332   |
| vb_q1     | 0.0051   |
| vb_q2     | 0.00474  |
| vb_q3     | 0.0256   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.39     |
| loss      | 1.04     |
| loss_q0   | 1.03     |
| loss_q1   | 1.05     |
| loss_q2   | 0.92     |
| loss_q3   | 1.15     |
| mse       | 1.02     |
| mse_q0    | 0.99     |
| mse_q1    | 1.04     |
| mse_q2    | 0.916    |
| mse_q3    | 1.13     |
| samples   | 3.46e+03 |
| step      | 26       |
| vb        | 0.0193   |
| vb_q0     | 0.0371   |
| vb_q1     | 0.00516  |
| vb_q2     | 0.00464  |
| vb_q3     | 0.0247   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.15     |
| loss      | 1.07     |
| loss_q0   | 1.08     |
| loss_q1   | 1.01     |
| loss_q2   | 1.11     |
| loss_q3   | 1.07     |
| mse       | 1.05     |
| mse_q0    | 1.03     |
| mse_q1    | 1.01     |
| mse_q2    | 1.1      |
| mse_q3    | 1.05     |
| samples   | 3.58e+03 |
| step      | 27       |
| vb        | 0.0213   |
| vb_q0     | 0.0535   |
| vb_q1     | 0.00512  |
| vb_q2     | 0.0056   |
| vb_q3     | 0.0178   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.1      |
| loss      | 1.02     |
| loss_q0   | 1.05     |
| loss_q1   | 0.877    |
| loss_q2   | 1.16     |
| loss_q3   | 0.951    |
| mse       | 1        |
| mse_q0    | 1.02     |
| mse_q1    | 0.873    |
| mse_q2    | 1.15     |
| mse_q3    | 0.927    |
| samples   | 3.71e+03 |
| step      | 28       |
| vb        | 0.0161   |
| vb_q0     | 0.0324   |
| vb_q1     | 0.00437  |
| vb_q2     | 0.00597  |
| vb_q3     | 0.0248   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.13     |
| loss      | 1.03     |
| loss_q0   | 0.898    |
| loss_q1   | 1.03     |
| loss_q2   | 1.06     |
| loss_q3   | 1.05     |
| mse       | 1.02     |
| mse_q0    | 0.885    |
| mse_q1    | 1.03     |
| mse_q2    | 1.05     |
| mse_q3    | 1.03     |
| samples   | 3.84e+03 |
| step      | 29       |
| vb        | 0.0106   |
| vb_q0     | 0.0122   |
| vb_q1     | 0.00512  |
| vb_q2     | 0.00539  |
| vb_q3     | 0.0237   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.26     |
| loss      | 1.05     |
| loss_q0   | 1.2      |
| loss_q1   | 1.13     |
| loss_q2   | 0.906    |
| loss_q3   | 0.999    |
| mse       | 1.03     |
| mse_q0    | 1.17     |
| mse_q1    | 1.12     |
| mse_q2    | 0.902    |
| mse_q3    | 0.941    |
| samples   | 3.97e+03 |
| step      | 30       |
| vb        | 0.0256   |
| vb_q0     | 0.0284   |
| vb_q1     | 0.00559  |
| vb_q2     | 0.00464  |
| vb_q3     | 0.0579   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.875    |
| loss      | 0.972    |
| loss_q0   | 0.837    |
| loss_q1   | 0.998    |
| loss_q2   | 1.16     |
| loss_q3   | 0.857    |
| mse       | 0.949    |
| mse_q0    | 0.82     |
| mse_q1    | 0.993    |
| mse_q2    | 1.16     |
| mse_q3    | 0.792    |
| samples   | 4.1e+03  |
| step      | 31       |
| vb        | 0.0238   |
| vb_q0     | 0.0175   |
| vb_q1     | 0.00485  |
| vb_q2     | 0.00585  |
| vb_q3     | 0.0641   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 0.954    |
| loss      | 1.07     |
| loss_q0   | 1.32     |
| loss_q1   | 1.06     |
| loss_q2   | 1.01     |
| loss_q3   | 0.905    |
| mse       | 1.05     |
| mse_q0    | 1.28     |
| mse_q1    | 1.05     |
| mse_q2    | 1        |
| mse_q3    | 0.886    |
| samples   | 4.22e+03 |
| step      | 32       |
| vb        | 0.0193   |
| vb_q0     | 0.0446   |
| vb_q1     | 0.00511  |
| vb_q2     | 0.00524  |
| vb_q3     | 0.0187   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.22     |
| loss      | 1.05     |
| loss_q0   | 1        |
| loss_q1   | 0.947    |
| loss_q2   | 1.15     |
| loss_q3   | 1.14     |
| mse       | 1.02     |
| mse_q0    | 0.973    |
| mse_q1    | 0.942    |
| mse_q2    | 1.14     |
| mse_q3    | 1.1      |
| samples   | 4.35e+03 |
| step      | 33       |
| vb        | 0.0245   |
| vb_q0     | 0.0291   |
| vb_q1     | 0.00465  |
| vb_q2     | 0.00575  |
| vb_q3     | 0.0478   |
------------------------
saving model 0...
saving model 0.9999...
------------------------
| grad_norm | 1.19     |
| loss      | 1.08     |
| loss_q0   | 1.19     |
| loss_q1   | 1.15     |
| loss_q2   | 1.03     |
| loss_q3   | 0.892    |
| mse       | 1.06     |
| mse_q0    | 1.17     |
| mse_q1    | 1.15     |
| mse_q2    | 1.02     |
| mse_q3    | 0.858    |
| samples   | 4.48e+03 |
| step      | 34       |
| vb        | 0.0176   |
| vb_q0     | 0.0264   |
| vb_q1     | 0.0058   |
| vb_q2     | 0.00518  |
| vb_q3     | 0.0336   |
------------------------
saving model 0...
saving model 0.9999...
